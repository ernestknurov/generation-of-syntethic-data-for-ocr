{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import EmnistDataset, EmnistMapping, emnist_transform, augmentations, FontDataset, font_transform\n",
    "from config import EMNIST_TRAIN_PATH, EMNIST_TEST_PATH, EMNIST_MAPPING_PATH, FONTS_DATASET_PATH, FONTS_MAPPING_PATH\n",
    "\n",
    "# Define constants\n",
    "batch_size = 64 * 1\n",
    "image_size = 28\n",
    "nz = 100  # Size of z latent vector (i.e., size of generator input)\n",
    "num_epochs = 1000\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "lambda_gp = 5  # Gradient penalty lambda\n",
    "n_classes = 47  # Number of classes in EMNIST balanced split\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = EmnistDataset(EMNIST_TRAIN_PATH, augmentations, limit=256)\n",
    "dataset = FontDataset(FONTS_DATASET_PATH, FONTS_MAPPING_PATH, font_transform)\n",
    "mapping = EmnistMapping(EMNIST_MAPPING_PATH)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Validate DataLoader\n",
    "for images, labels in dataloader:\n",
    "    print(images.shape)  # Should be [batch_size, 1, 28, 28]\n",
    "    print(labels.shape)  # Should be [batch_size]\n",
    "    break  # Exit after printing the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tensor_stats(tensor, name):\n",
    "    print(f\"{name}: min={tensor.min().item()}, max={tensor.max().item()}, mean={tensor.mean().item()}, std={tensor.std().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grfgd: min=-1.0, max=1.0, mean=-0.6653761863708496, std=0.6649017333984375\n"
     ]
    }
   ],
   "source": [
    "print_tensor_stats(dataset[0][0],\"grfgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, mapping=None, title=None):\n",
    "    # Create a figure with subplots in a grid\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "\n",
    "    ax.imshow(image[0][0].numpy(), cmap='gray')\n",
    "    # ax.set_title(mapping[image[1].item()])\n",
    "    ax.axis('off')  # Hide axes\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASIAAAEiCAYAAABdvt+2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAJOElEQVR4nO3cT4gUdB/H8Z3diU0Pu7oWEYJGBBFmgjcRFgMhYhXNQ5cSvHSTLoEQdPBQdOggXryLEh6ERCLs1MHYi9ChxYPgqkUQQfmvtlxaZ56zPYffN93ts7Pzep0//Jqe7N0cvs90+v1+fwQgaDT9AQCECIgTIiBOiIA4IQLihAiIEyIgToiAOCEC4rrVYafTWcnPAaxB1f/jhm9EQJwQAXFCBMQJERAnRECcEAFxQgTECREQJ0RAXPmyGp5UtzvYf9yWlpbSH2HN8o0IiBMiIE6IgDghAuKECIgTIiBOiIA4IQLiBvvCjP8zOlr7b8umTZuam8nJydJb1d309HRzMzExUXprOfV6vdLuzJkzzc0PP/xQeqv6E6rDwjciIE6IgDghAuKECIgTIiBOiIA4IQLihAiIEyIgrtMvnnh2Op2V/ixD6+mnn25u3njjjdJb77zzTmm3Z8+e5mbDhg2lt6p/NsbGxkq71Wp+fr65OX78eOmt8+fPl3aLi4ul3WpVvSD3jQiIEyIgToiAOCEC4oQIiBMiIE6IgDghAuKECIhzWb2CqpfE+/bta24+++yz0lsvvvhiaVf5bNWr2KWlpdLu7t27zc2dO3dKb1VV/txWL8inpqaam++++6701ttvv13a3bp1q7RbrVxWAwNDiIA4IQLihAiIEyIgToiAOCEC4oQIiOumP8BatnXr1tLuyJEjzU31ULF6XHjjxo3m5v79+6W3vvnmm9Judna2uZmbmyu9VVU53Ny+fXvprU8//bS5qR7w8SjfiIA4IQLihAiIEyIgToiAOCEC4oQIiBMiIE6IgDiX1Y+h+rO5hw8fLu327t3b3Pz111+lty5cuFDaffzxx83N4uJi6a1ffvmltKu81+v1Sm8tp+vXr5d2Dx48aG6ql9U///xzaTcsfCMC4oQIiBMiIE6IgDghAuKECIgTIiBOiIC4Tr94gVU94ht0o6PtNs/MzJTe+vzzz0u7+fn55ubo0aOlt65cuVLaVY8V4UlUDzx9IwLihAiIEyIgToiAOCEC4oQIiBMiIE6IgDghAuL8VOw/jI+PNzfT09OltxYWFkq7EydONDcuplnLfCMC4oQIiBMiIE6IgDghAuKECIgTIiBOiIA4IQLiXFb/w/PPP9/cvP7666W3ZmdnS7tLly41Ny6mWct8IwLihAiIEyIgToiAOCEC4oQIiBMiIE6IgLihOWjsdmt/qwcOHGhuXnnlldJbc3NzpZ1jRYadb0RAnBABcUIExAkRECdEQJwQAXFCBMQJERAnREDc0FxWJ/zxxx+l3bp165qbhYWF0lsPHz4s7Xq9XmkH/wXfiIA4IQLihAiIEyIgToiAOCEC4oQIiBMiIE6IgLhOv9/vl4adzkp/llXhtddea25Onz5demvz5s2l3eXLl5ub77//vvRWdVf5Pe179+6V3rp7925pV7n6dvG9thTz4hsRkCdEQJwQAXFCBMQJERAnRECcEAFxQgTEOWj8h/Hx8ebm0KFDpbdOnDhR2k1OTpZ2Fffv3y/tbt++3dxcvXq19FblOHJkpHZsWX2remxZ+bneyj/zkZHa/7YOMh/loBEYGEIExAkRECdEQJwQAXFCBMQJERAnRECcEAFxLqtX0LPPPlvabdy4sbnZtm1b6a3t27eXdpWfxH311VdLb1U+/8jIyMjExERpV1G9IF9YWGhuqpfVX3/9dXPzySeflN66ceNGaVe9TF6tXFYDA0OIgDghAuKECIgTIiBOiIA4IQLihAiIEyIgzmX1gBgdrf03o7qrXENXL6aX8+q7cvH9b/6aY2Njzc3U1FTprfXr1zc3586dK7117Nix0u7XX38t7VYrl9XAwBAiIE6IgDghAuKECIgTIiBOiIA4IQLiHDTyxJbz2LJ6RDk5OVnadbvd5ubw4cOltz788MPm5tq1a6W39u/fX9pdv369tFutHDQCA0OIgDghAuKECIgTIiBOiIA4IQLihAiIEyIgzmU1Q+/ll18u7ebm5pqbmzdvlt6amZkp7VxWA/xHhAiIEyIgToiAOCEC4oQIiBMiIE6IgDghAuLaP+jLY6v+lnNFr9dbtrd41MOHD9MfYej5RgTECREQJ0RAnBABcUIExAkRECdEQJwQAXEOGlfQm2++Wdo99dRTzc3s7Gzprd9++620c8S3MhyePh7fiIA4IQLihAiIEyIgToiAOCEC4oQIiBMiIE6IgDiX1Y9hbGystPvoo49KuxdeeKG5+fbbb0tvnT17trT78ssvm5thub6enJws7fr9fnPz448/lt76888/S7th4RsRECdEQJwQAXFCBMQJERAnRECcEAFxQgTEOWh8DNVDv4sXL5Z277//fnNz6NCh0lv79u0r7SoHjefOnSu9dfny5dKu8jO2y31E2e22/4jPzMyU3lpaWmpufvrpp9Jbi4uLpd2w8I0IiBMiIE6IgDghAuKECIgTIiBOiIA4IQLihAiI6/Qrv385MjLS6XRW+rOsOc8880xpV7nsPXr0aOmtLVu2lHYbNmxobu7cuVN6q3pZXbnU/uqrr0pv/f3336XdunXrmpvjx4+X3nrppZeamw8++KD01vz8fGlX/Ndz1ap+ft+IgDghAuKECIgTIiBOiIA4IQLihAiIEyIgToiAOJfVq8D4+Hhzs3nz5tJbO3bsKO3efffd5mb37t2lt6ampkq727dvNzdnz54tvfX777+XdhMTE83NwYMHS2+dOnWquTl58mTprcrvX68FLquBgSFEQJwQAXFCBMQJERAnRECcEAFxQgTEOWgcUmNjY83N1q1bS2+99dZbpd2uXbuam507d5beeu6550q7Xq/X3Fy4cKH01nvvvdfcPHjwoPTWsHDQCAwMIQLihAiIEyIgToiAOCEC4oQIiBMiIE6IgDiX1Tyxbrdb2m3cuLG52bJlS+mt6enp0q7iiy++KO1u3bq1bH/NYeGyGhgYQgTECREQJ0RAnBABcUIExAkRECdEQJwQAXEuqxlI1WvuiqWlpWV7i0e5rAYGhhABcUIExAkRECdEQJwQAXFCBMQJERDnoBFYMQ4agYEhRECcEAFxQgTECREQJ0RAnBABcUIExAkREFf+vc3qhSTAv+UbERAnRECcEAFxQgTECREQJ0RAnBABcUIExAkREPc/XI3x8LcvRCEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28)\n"
     ]
    }
   ],
   "source": [
    "show_image(dataset[9])\n",
    "print(dataset[9][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Generator and Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, nz, n_classes, ngf, nc):\n",
    "        super(ConditionalGenerator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz + n_classes, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.InstanceNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 2, bias=False),\n",
    "            nn.InstanceNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, nc, 1, 1, 0, bias=False),  # Adjusted padding\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        label_embeddings = self.label_emb(labels).view(labels.size(0), -1, 1, 1)\n",
    "        gen_input = torch.cat((noise, label_embeddings), 1)\n",
    "        return self.main(gen_input)\n",
    "\n",
    "class ConditionalCritic(nn.Module):\n",
    "    def __init__(self, nc, ndf, n_classes):\n",
    "        super(ConditionalCritic, self).__init__()\n",
    "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc + n_classes, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 2, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 8, 1, 2, 1, 0, bias=False),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        label_embeddings = self.label_emb(labels).view(labels.size(0), -1, 1, 1)\n",
    "        label_embeddings = label_embeddings.repeat(1, 1, img.size(2), img.size(3))\n",
    "        d_input = torch.cat((img, label_embeddings), 1)\n",
    "        return self.main(d_input).view(-1, 1).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of channels in the training images. For grayscale images, this is 1\n",
    "nc = 1\n",
    "# Size of feature maps in generator\n",
    "ngf = 64 * 4\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64 * 4\n",
    "\n",
    "netG = ConditionalGenerator(nz, n_classes, ngf, nc).to(device)\n",
    "netD = ConditionalCritic(nc, ndf, n_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConditionalCritic(\n",
       "  (label_emb): Embedding(47, 47)\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(48, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "    (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(2048, 1, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weights\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Loss Function and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_upd_rate = 2\n",
    "image_show_rate = 256\n",
    "loss_show_rate = 256\n",
    "epoch_show_rate = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] Batch [0/23] Loss D: 12.267582893371582, Loss G: 0.256841242313385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/1000] Batch [0/23] Loss D: 0.00035611900966614485, Loss G: 11.995532035827637\n",
      "Epoch [3/1000] Batch [0/23] Loss D: 0.656411349773407, Loss G: 17.363399505615234\n",
      "Epoch [4/1000] Batch [0/23] Loss D: 1.180397868156433, Loss G: 13.890617370605469\n",
      "Epoch [5/1000] Batch [0/23] Loss D: 0.03047582134604454, Loss G: 9.911396026611328\n",
      "Epoch [6/1000] Batch [0/23] Loss D: 0.006901036482304335, Loss G: 3.1025161743164062\n",
      "Epoch [7/1000] Batch [0/23] Loss D: 0.032247986644506454, Loss G: 10.04847526550293\n",
      "Epoch [8/1000] Batch [0/23] Loss D: 0.14657720923423767, Loss G: 5.787108898162842\n",
      "Epoch [9/1000] Batch [0/23] Loss D: 0.05167573690414429, Loss G: 6.960891246795654\n",
      "Epoch [10/1000] Batch [0/23] Loss D: 0.16183623671531677, Loss G: 5.349616050720215\n",
      "Epoch [11/1000] Batch [0/23] Loss D: 0.012616629712283611, Loss G: 10.366363525390625\n",
      "Epoch [12/1000] Batch [0/23] Loss D: 0.004697762429714203, Loss G: 7.719142436981201\n",
      "Epoch [13/1000] Batch [0/23] Loss D: 0.04911820963025093, Loss G: 6.78813362121582\n",
      "Epoch [14/1000] Batch [0/23] Loss D: 0.061183810234069824, Loss G: 8.454690933227539\n",
      "Epoch [15/1000] Batch [0/23] Loss D: 0.01853124424815178, Loss G: 6.911707878112793\n",
      "Epoch [16/1000] Batch [0/23] Loss D: 0.011674866080284119, Loss G: 6.065345764160156\n",
      "Epoch [17/1000] Batch [0/23] Loss D: 0.04586319625377655, Loss G: 5.118824005126953\n",
      "Epoch [18/1000] Batch [0/23] Loss D: 0.049800921231508255, Loss G: 4.300725936889648\n",
      "Epoch [19/1000] Batch [0/23] Loss D: 0.24775759875774384, Loss G: 10.186577796936035\n",
      "Epoch [20/1000] Batch [0/23] Loss D: 0.06239769980311394, Loss G: 5.520049095153809\n",
      "Epoch [21/1000] Batch [0/23] Loss D: 0.012126258574426174, Loss G: 6.543292045593262\n",
      "Epoch [22/1000] Batch [0/23] Loss D: 0.004912856966257095, Loss G: 6.777012825012207\n",
      "Epoch [23/1000] Batch [0/23] Loss D: 0.001676964689977467, Loss G: 9.016448020935059\n",
      "Epoch [24/1000] Batch [0/23] Loss D: 0.022883297875523567, Loss G: 8.896286010742188\n",
      "Epoch [25/1000] Batch [0/23] Loss D: 0.025458578020334244, Loss G: 4.2609357833862305\n",
      "Epoch [26/1000] Batch [0/23] Loss D: 0.08635108917951584, Loss G: 7.4837188720703125\n",
      "Epoch [27/1000] Batch [0/23] Loss D: 0.022967034950852394, Loss G: 4.228553771972656\n",
      "Epoch [28/1000] Batch [0/23] Loss D: 0.00451517291367054, Loss G: 9.4706449508667\n",
      "Epoch [29/1000] Batch [0/23] Loss D: 0.06226890906691551, Loss G: 8.460478782653809\n",
      "Epoch [30/1000] Batch [0/23] Loss D: 0.030449997633695602, Loss G: 6.370767116546631\n",
      "Epoch [31/1000] Batch [0/23] Loss D: 0.02217061072587967, Loss G: 7.293806076049805\n",
      "Epoch [32/1000] Batch [0/23] Loss D: 0.17999033629894257, Loss G: 12.795387268066406\n",
      "Epoch [33/1000] Batch [0/23] Loss D: 0.021326158195734024, Loss G: 5.858851432800293\n",
      "Epoch [34/1000] Batch [0/23] Loss D: 0.001287249499000609, Loss G: 7.188692569732666\n",
      "Epoch [35/1000] Batch [0/23] Loss D: 0.14905516803264618, Loss G: 9.851435661315918\n",
      "Epoch [36/1000] Batch [0/23] Loss D: 0.0573955774307251, Loss G: 7.00294303894043\n",
      "Epoch [37/1000] Batch [0/23] Loss D: 0.021852826699614525, Loss G: 11.477777481079102\n",
      "Epoch [38/1000] Batch [0/23] Loss D: 0.006065599154680967, Loss G: 6.597668647766113\n",
      "Epoch [39/1000] Batch [0/23] Loss D: 0.05928437039256096, Loss G: 4.3141069412231445\n",
      "Epoch [40/1000] Batch [0/23] Loss D: 0.005413970444351435, Loss G: 7.403443336486816\n",
      "Epoch [41/1000] Batch [0/23] Loss D: 0.001999392407014966, Loss G: 10.546913146972656\n",
      "Epoch [42/1000] Batch [0/23] Loss D: 0.05097891017794609, Loss G: 7.4304680824279785\n",
      "Epoch [43/1000] Batch [0/23] Loss D: 0.01982543244957924, Loss G: 6.004794120788574\n",
      "Epoch [44/1000] Batch [0/23] Loss D: 0.3212979733943939, Loss G: 6.609950065612793\n",
      "Epoch [45/1000] Batch [0/23] Loss D: 0.08244101703166962, Loss G: 7.474076271057129\n",
      "Epoch [46/1000] Batch [0/23] Loss D: 0.28022730350494385, Loss G: 12.905861854553223\n",
      "Epoch [47/1000] Batch [0/23] Loss D: 0.004475571680814028, Loss G: 6.841128349304199\n",
      "Epoch [48/1000] Batch [0/23] Loss D: 0.005634660832583904, Loss G: 4.241665840148926\n",
      "Epoch [49/1000] Batch [0/23] Loss D: 0.053675420582294464, Loss G: 7.736854076385498\n",
      "Epoch [50/1000] Batch [0/23] Loss D: 0.07055626064538956, Loss G: 9.362054824829102\n",
      "Epoch [51/1000] Batch [0/23] Loss D: 0.006834136322140694, Loss G: 5.1299357414245605\n",
      "Epoch [52/1000] Batch [0/23] Loss D: 0.0983467623591423, Loss G: 7.677975177764893\n",
      "Epoch [53/1000] Batch [0/23] Loss D: 0.018705645576119423, Loss G: 8.630770683288574\n",
      "Epoch [54/1000] Batch [0/23] Loss D: 0.001423281035386026, Loss G: 5.00225305557251\n",
      "Epoch [55/1000] Batch [0/23] Loss D: 0.0016056080348789692, Loss G: 7.5171732902526855\n",
      "Epoch [56/1000] Batch [0/23] Loss D: 0.054195936769247055, Loss G: 9.390618324279785\n",
      "Epoch [57/1000] Batch [0/23] Loss D: 0.00550851272419095, Loss G: 9.675337791442871\n",
      "Epoch [58/1000] Batch [0/23] Loss D: 0.02430068328976631, Loss G: 5.3386688232421875\n",
      "Epoch [59/1000] Batch [0/23] Loss D: 0.04576120153069496, Loss G: 5.221419334411621\n",
      "Epoch [60/1000] Batch [0/23] Loss D: 0.020709428936243057, Loss G: 15.48134708404541\n",
      "Epoch [61/1000] Batch [0/23] Loss D: 0.0035859690979123116, Loss G: 7.2187418937683105\n",
      "Epoch [62/1000] Batch [0/23] Loss D: 0.0031963037326931953, Loss G: 8.307923316955566\n",
      "Epoch [63/1000] Batch [0/23] Loss D: 0.14232870936393738, Loss G: 3.545576810836792\n",
      "Epoch [64/1000] Batch [0/23] Loss D: 0.02471679449081421, Loss G: 15.41392707824707\n",
      "Epoch [65/1000] Batch [0/23] Loss D: 0.005038673523813486, Loss G: 10.49917984008789\n",
      "Epoch [66/1000] Batch [0/23] Loss D: 0.0038012214936316013, Loss G: 9.367197036743164\n",
      "Epoch [67/1000] Batch [0/23] Loss D: 0.002139124320819974, Loss G: 9.91769790649414\n",
      "Epoch [68/1000] Batch [0/23] Loss D: 11.024412155151367, Loss G: 4.835507869720459\n",
      "Epoch [69/1000] Batch [0/23] Loss D: 0.025462264195084572, Loss G: 3.8762824535369873\n",
      "Epoch [70/1000] Batch [0/23] Loss D: 0.024818381294608116, Loss G: 10.918530464172363\n",
      "Epoch [71/1000] Batch [0/23] Loss D: 0.028148718178272247, Loss G: 2.1732895374298096\n",
      "Epoch [72/1000] Batch [0/23] Loss D: 0.006879113148897886, Loss G: 11.064586639404297\n",
      "Epoch [73/1000] Batch [0/23] Loss D: 0.0023900975938886404, Loss G: 7.240927696228027\n",
      "Epoch [74/1000] Batch [0/23] Loss D: 0.0028106544632464647, Loss G: 10.182093620300293\n",
      "Epoch [75/1000] Batch [0/23] Loss D: 0.12553712725639343, Loss G: 4.286864280700684\n",
      "Epoch [76/1000] Batch [0/23] Loss D: 0.00856385100632906, Loss G: 9.420519828796387\n",
      "Epoch [77/1000] Batch [0/23] Loss D: 0.028826268389821053, Loss G: 12.06387710571289\n",
      "Epoch [78/1000] Batch [0/23] Loss D: 0.003366599790751934, Loss G: 7.489400863647461\n",
      "Epoch [79/1000] Batch [0/23] Loss D: 0.06783772259950638, Loss G: 7.145112991333008\n",
      "Epoch [80/1000] Batch [0/23] Loss D: 0.16162465512752533, Loss G: 8.985575675964355\n",
      "Epoch [81/1000] Batch [0/23] Loss D: 0.6196892261505127, Loss G: 9.727533340454102\n",
      "Epoch [82/1000] Batch [0/23] Loss D: 0.36838120222091675, Loss G: 5.028081893920898\n",
      "Epoch [83/1000] Batch [0/23] Loss D: 0.01034401636570692, Loss G: 7.768588066101074\n",
      "Epoch [84/1000] Batch [0/23] Loss D: 0.013846272602677345, Loss G: 4.521047592163086\n",
      "Epoch [85/1000] Batch [0/23] Loss D: 0.9152176380157471, Loss G: 11.94361686706543\n",
      "Epoch [86/1000] Batch [0/23] Loss D: 0.045753467828035355, Loss G: 2.017965316772461\n",
      "Epoch [87/1000] Batch [0/23] Loss D: 0.08409056812524796, Loss G: 6.184451580047607\n",
      "Epoch [88/1000] Batch [0/23] Loss D: 0.0434427484869957, Loss G: 1.4775824546813965\n",
      "Epoch [89/1000] Batch [0/23] Loss D: 0.10772647708654404, Loss G: 7.768170356750488\n",
      "Epoch [90/1000] Batch [0/23] Loss D: 0.026737887412309647, Loss G: 11.451428413391113\n",
      "Epoch [91/1000] Batch [0/23] Loss D: 0.10542646795511246, Loss G: 8.03289794921875\n",
      "Epoch [92/1000] Batch [0/23] Loss D: 0.0030383197590708733, Loss G: 8.336231231689453\n",
      "Epoch [93/1000] Batch [0/23] Loss D: 0.2176501601934433, Loss G: 6.717428207397461\n",
      "Epoch [94/1000] Batch [0/23] Loss D: 0.05084649845957756, Loss G: 2.218708038330078\n",
      "Epoch [95/1000] Batch [0/23] Loss D: 0.33558374643325806, Loss G: 18.84751319885254\n",
      "Epoch [96/1000] Batch [0/23] Loss D: 0.19082991778850555, Loss G: 18.262123107910156\n",
      "Epoch [97/1000] Batch [0/23] Loss D: 0.01731463521718979, Loss G: 8.627403259277344\n",
      "Epoch [98/1000] Batch [0/23] Loss D: 0.0007447989191859961, Loss G: 5.4646406173706055\n",
      "Epoch [99/1000] Batch [0/23] Loss D: 0.009245317429304123, Loss G: 11.380373001098633\n",
      "Epoch [100/1000] Batch [0/23] Loss D: 0.06353160738945007, Loss G: 7.968088626861572\n",
      "Epoch [101/1000] Batch [0/23] Loss D: 0.14355695247650146, Loss G: 10.575082778930664\n",
      "Epoch [102/1000] Batch [0/23] Loss D: 0.0038882808294147253, Loss G: 7.826115608215332\n",
      "Epoch [103/1000] Batch [0/23] Loss D: 0.00042132174712605774, Loss G: 14.472755432128906\n",
      "Epoch [104/1000] Batch [0/23] Loss D: 0.02806040830910206, Loss G: 3.9432854652404785\n",
      "Epoch [105/1000] Batch [0/23] Loss D: 0.04750956594944, Loss G: 4.9373321533203125\n",
      "Epoch [106/1000] Batch [0/23] Loss D: 0.06689947098493576, Loss G: 7.046566486358643\n",
      "Epoch [107/1000] Batch [0/23] Loss D: 0.007633415516465902, Loss G: 3.6196250915527344\n",
      "Epoch [108/1000] Batch [0/23] Loss D: 1.6934682130813599, Loss G: 12.277308464050293\n",
      "Epoch [109/1000] Batch [0/23] Loss D: 0.017105720937252045, Loss G: 9.155780792236328\n",
      "Epoch [110/1000] Batch [0/23] Loss D: 0.023807022720575333, Loss G: 10.363452911376953\n",
      "Epoch [111/1000] Batch [0/23] Loss D: 0.0036118002608418465, Loss G: 8.305366516113281\n",
      "Epoch [112/1000] Batch [0/23] Loss D: 0.03125333413481712, Loss G: 2.4704341888427734\n",
      "Epoch [113/1000] Batch [0/23] Loss D: 0.08755572140216827, Loss G: 6.62819242477417\n",
      "Epoch [114/1000] Batch [0/23] Loss D: 0.1448226273059845, Loss G: 8.639543533325195\n",
      "Epoch [115/1000] Batch [0/23] Loss D: 0.10275540500879288, Loss G: 9.505264282226562\n",
      "Epoch [116/1000] Batch [0/23] Loss D: 0.0010574618354439735, Loss G: 9.099006652832031\n",
      "Epoch [117/1000] Batch [0/23] Loss D: 0.001530917827039957, Loss G: 5.239507675170898\n",
      "Epoch [118/1000] Batch [0/23] Loss D: 0.01512268465012312, Loss G: 6.659377098083496\n",
      "Epoch [119/1000] Batch [0/23] Loss D: 0.01511102169752121, Loss G: 7.44603157043457\n",
      "Epoch [120/1000] Batch [0/23] Loss D: 0.024098824709653854, Loss G: 6.156243324279785\n",
      "Epoch [121/1000] Batch [0/23] Loss D: 0.13378189504146576, Loss G: 0.9534116387367249\n",
      "Epoch [122/1000] Batch [0/23] Loss D: 0.0032239132560789585, Loss G: 2.7533340454101562\n",
      "Epoch [123/1000] Batch [0/23] Loss D: 0.0003787199384532869, Loss G: 14.34182357788086\n",
      "Epoch [124/1000] Batch [0/23] Loss D: 0.007027131505310535, Loss G: 8.45136833190918\n",
      "Epoch [125/1000] Batch [0/23] Loss D: 0.00974264182150364, Loss G: 8.271902084350586\n",
      "Epoch [126/1000] Batch [0/23] Loss D: 0.12490967661142349, Loss G: 5.380697250366211\n",
      "Epoch [127/1000] Batch [0/23] Loss D: 0.0019195183413103223, Loss G: 5.550333023071289\n",
      "Epoch [128/1000] Batch [0/23] Loss D: 0.0003083095944020897, Loss G: 5.937713623046875\n",
      "Epoch [129/1000] Batch [0/23] Loss D: 0.00595091562718153, Loss G: 6.300267696380615\n",
      "Epoch [130/1000] Batch [0/23] Loss D: 0.13266858458518982, Loss G: 5.680880546569824\n",
      "Epoch [131/1000] Batch [0/23] Loss D: 0.00589842488989234, Loss G: 7.057042121887207\n",
      "Epoch [132/1000] Batch [0/23] Loss D: 0.006802510470151901, Loss G: 8.822635650634766\n",
      "Epoch [133/1000] Batch [0/23] Loss D: 0.008131012320518494, Loss G: 9.727192878723145\n",
      "Epoch [134/1000] Batch [0/23] Loss D: 0.00031535275047644973, Loss G: 6.333161354064941\n",
      "Epoch [135/1000] Batch [0/23] Loss D: 0.009919618256390095, Loss G: 7.796599388122559\n",
      "Epoch [136/1000] Batch [0/23] Loss D: 0.006350730545818806, Loss G: 2.178485870361328\n",
      "Epoch [137/1000] Batch [0/23] Loss D: 0.007992750033736229, Loss G: 8.342793464660645\n",
      "Epoch [138/1000] Batch [0/23] Loss D: 0.0003876348491758108, Loss G: 6.820767402648926\n",
      "Epoch [139/1000] Batch [0/23] Loss D: 0.0012011949438601732, Loss G: 6.857144355773926\n",
      "Epoch [140/1000] Batch [0/23] Loss D: 0.02216808870434761, Loss G: 6.430416584014893\n",
      "Epoch [141/1000] Batch [0/23] Loss D: 0.011561917141079903, Loss G: 9.544947624206543\n",
      "Epoch [142/1000] Batch [0/23] Loss D: 0.006824064068496227, Loss G: 6.842189788818359\n",
      "Epoch [143/1000] Batch [0/23] Loss D: 0.2406758815050125, Loss G: 11.168318748474121\n",
      "Epoch [144/1000] Batch [0/23] Loss D: 0.0024126097559928894, Loss G: 8.2432861328125\n",
      "Epoch [145/1000] Batch [0/23] Loss D: 0.0029867952689528465, Loss G: 8.09027099609375\n",
      "Epoch [146/1000] Batch [0/23] Loss D: 0.037746161222457886, Loss G: 9.291622161865234\n",
      "Epoch [147/1000] Batch [0/23] Loss D: 0.0018675086321309209, Loss G: 8.62380599975586\n",
      "Epoch [148/1000] Batch [0/23] Loss D: 0.012477187439799309, Loss G: 2.895387649536133\n",
      "Epoch [149/1000] Batch [0/23] Loss D: 0.009658509865403175, Loss G: 6.740473747253418\n",
      "Epoch [150/1000] Batch [0/23] Loss D: 0.004853312391787767, Loss G: 5.966823577880859\n",
      "Epoch [151/1000] Batch [0/23] Loss D: 0.001103076385334134, Loss G: 7.164714813232422\n",
      "Epoch [152/1000] Batch [0/23] Loss D: 0.005934298969805241, Loss G: 7.28312349319458\n",
      "Epoch [153/1000] Batch [0/23] Loss D: 0.0017676836578175426, Loss G: 6.184943675994873\n",
      "Epoch [154/1000] Batch [0/23] Loss D: 0.0029003601521253586, Loss G: 7.19974422454834\n",
      "Epoch [155/1000] Batch [0/23] Loss D: 0.00281522492878139, Loss G: 5.740355014801025\n",
      "Epoch [156/1000] Batch [0/23] Loss D: 0.0005566963227465749, Loss G: 5.202058792114258\n",
      "Epoch [157/1000] Batch [0/23] Loss D: 0.0003596813476178795, Loss G: 11.335376739501953\n",
      "Epoch [158/1000] Batch [0/23] Loss D: 0.002712975023314357, Loss G: 5.610939979553223\n",
      "Epoch [159/1000] Batch [0/23] Loss D: 0.0006386724417097867, Loss G: 8.177492141723633\n",
      "Epoch [160/1000] Batch [0/23] Loss D: 0.003043585689738393, Loss G: 3.8940749168395996\n",
      "Epoch [161/1000] Batch [0/23] Loss D: 0.009437494911253452, Loss G: 14.54393196105957\n",
      "Epoch [162/1000] Batch [0/23] Loss D: 0.007790740113705397, Loss G: 9.678274154663086\n",
      "Epoch [163/1000] Batch [0/23] Loss D: 0.003967857453972101, Loss G: 5.420884132385254\n",
      "Epoch [164/1000] Batch [0/23] Loss D: 0.0021868485491722822, Loss G: 9.126212120056152\n",
      "Epoch [165/1000] Batch [0/23] Loss D: 0.00011845908011309803, Loss G: 9.916915893554688\n",
      "Epoch [166/1000] Batch [0/23] Loss D: 0.0014088544994592667, Loss G: 9.959371566772461\n",
      "Epoch [167/1000] Batch [0/23] Loss D: 0.001213746378198266, Loss G: 9.056586265563965\n",
      "Epoch [168/1000] Batch [0/23] Loss D: 0.0015498907305300236, Loss G: 7.418663024902344\n",
      "Epoch [169/1000] Batch [0/23] Loss D: 0.007209711242467165, Loss G: 7.684880256652832\n",
      "Epoch [170/1000] Batch [0/23] Loss D: 0.0244321059435606, Loss G: 9.67221736907959\n",
      "Epoch [171/1000] Batch [0/23] Loss D: 0.0007860579062253237, Loss G: 7.791496276855469\n",
      "Epoch [172/1000] Batch [0/23] Loss D: 0.0006677976343780756, Loss G: 9.028600692749023\n",
      "Epoch [173/1000] Batch [0/23] Loss D: 0.0005990566569380462, Loss G: 8.80465316772461\n",
      "Epoch [174/1000] Batch [0/23] Loss D: 0.0011481756810098886, Loss G: 7.961334705352783\n",
      "Epoch [175/1000] Batch [0/23] Loss D: 0.0024605069775134325, Loss G: 17.91351890563965\n",
      "Epoch [176/1000] Batch [0/23] Loss D: 8.109844202408567e-06, Loss G: 10.877925872802734\n",
      "Epoch [177/1000] Batch [0/23] Loss D: 0.00023808663536328822, Loss G: 10.857627868652344\n",
      "Epoch [178/1000] Batch [0/23] Loss D: 0.0007676587556488812, Loss G: 10.044939041137695\n",
      "Epoch [179/1000] Batch [0/23] Loss D: 0.001806285115890205, Loss G: 7.199187278747559\n",
      "Epoch [180/1000] Batch [0/23] Loss D: 0.000519029563292861, Loss G: 7.26387357711792\n",
      "Epoch [181/1000] Batch [0/23] Loss D: 0.00031033961568027735, Loss G: 8.950632095336914\n",
      "Epoch [182/1000] Batch [0/23] Loss D: 0.003623505588620901, Loss G: 10.69426155090332\n",
      "Epoch [183/1000] Batch [0/23] Loss D: 0.00013927275722380728, Loss G: 14.913383483886719\n",
      "Epoch [184/1000] Batch [0/23] Loss D: 0.03898180276155472, Loss G: 7.606297016143799\n",
      "Epoch [185/1000] Batch [0/23] Loss D: 0.0018268547719344497, Loss G: 4.742962837219238\n",
      "Epoch [186/1000] Batch [0/23] Loss D: 0.00011865903798025101, Loss G: 9.955343246459961\n",
      "Epoch [187/1000] Batch [0/23] Loss D: 0.0009885848267003894, Loss G: 12.946636199951172\n",
      "Epoch [188/1000] Batch [0/23] Loss D: 0.00015110075764823705, Loss G: 10.458056449890137\n",
      "Epoch [189/1000] Batch [0/23] Loss D: 0.0008791867876425385, Loss G: 10.149738311767578\n",
      "Epoch [190/1000] Batch [0/23] Loss D: 0.0014101550914347172, Loss G: 8.15054988861084\n",
      "Epoch [191/1000] Batch [0/23] Loss D: 1.9211721420288086, Loss G: 20.773319244384766\n",
      "Epoch [192/1000] Batch [0/23] Loss D: 0.00180733110755682, Loss G: 12.712760925292969\n",
      "Epoch [193/1000] Batch [0/23] Loss D: 1.946596967172809e-05, Loss G: 27.743999481201172\n",
      "Epoch [194/1000] Batch [0/23] Loss D: 0.06159002333879471, Loss G: 11.308332443237305\n",
      "Epoch [195/1000] Batch [0/23] Loss D: 0.0001704013702692464, Loss G: 17.66324234008789\n",
      "Epoch [196/1000] Batch [0/23] Loss D: 3.464559267740697e-05, Loss G: 16.6591854095459\n",
      "Epoch [197/1000] Batch [0/23] Loss D: 0.001152019132860005, Loss G: 15.182631492614746\n",
      "Epoch [198/1000] Batch [0/23] Loss D: 4.8822141252458096e-05, Loss G: 17.44768714904785\n",
      "Epoch [199/1000] Batch [0/23] Loss D: 2.184498225688003e-05, Loss G: 26.663280487060547\n",
      "Epoch [200/1000] Batch [0/23] Loss D: 0.04011394828557968, Loss G: 12.864972114562988\n",
      "Epoch [201/1000] Batch [0/23] Loss D: 0.07260356843471527, Loss G: 10.592638969421387\n",
      "Epoch [202/1000] Batch [0/23] Loss D: 0.008211418986320496, Loss G: 22.68185806274414\n",
      "Epoch [203/1000] Batch [0/23] Loss D: 0.002405793871730566, Loss G: 7.792956352233887\n",
      "Epoch [204/1000] Batch [0/23] Loss D: 0.00024571348330937326, Loss G: 9.535818099975586\n",
      "Epoch [205/1000] Batch [0/23] Loss D: 0.005422751419246197, Loss G: 10.18959903717041\n",
      "Epoch [206/1000] Batch [0/23] Loss D: 0.007257819175720215, Loss G: 7.709916114807129\n",
      "Epoch [207/1000] Batch [0/23] Loss D: 0.07488688826560974, Loss G: 5.737310409545898\n",
      "Epoch [208/1000] Batch [0/23] Loss D: 0.001148546813055873, Loss G: 10.011935234069824\n",
      "Epoch [209/1000] Batch [0/23] Loss D: 0.003920037765055895, Loss G: 6.668004035949707\n",
      "Epoch [210/1000] Batch [0/23] Loss D: 0.04549609124660492, Loss G: 6.193900108337402\n",
      "Epoch [211/1000] Batch [0/23] Loss D: 0.0031432360410690308, Loss G: 4.777318477630615\n",
      "Epoch [212/1000] Batch [0/23] Loss D: 0.002070504007861018, Loss G: 4.574963092803955\n",
      "Epoch [213/1000] Batch [0/23] Loss D: 0.004048350267112255, Loss G: 9.00284481048584\n",
      "Epoch [214/1000] Batch [0/23] Loss D: 0.5212627649307251, Loss G: 20.650310516357422\n",
      "Epoch [215/1000] Batch [0/23] Loss D: 0.7096591591835022, Loss G: 23.92976188659668\n",
      "Epoch [216/1000] Batch [0/23] Loss D: 0.016772659495472908, Loss G: 8.157109260559082\n",
      "Epoch [217/1000] Batch [0/23] Loss D: 0.0013969609281048179, Loss G: 5.041412830352783\n",
      "Epoch [218/1000] Batch [0/23] Loss D: 0.04310458526015282, Loss G: 8.537849426269531\n",
      "Epoch [219/1000] Batch [0/23] Loss D: 0.004685442894697189, Loss G: 10.45426082611084\n",
      "Epoch [220/1000] Batch [0/23] Loss D: 1.0803979635238647, Loss G: 28.903568267822266\n",
      "Epoch [221/1000] Batch [0/23] Loss D: 0.05141216516494751, Loss G: 6.529512405395508\n",
      "Epoch [222/1000] Batch [0/23] Loss D: 0.00038632750511169434, Loss G: 23.559717178344727\n",
      "Epoch [223/1000] Batch [0/23] Loss D: 0.0006451126537285745, Loss G: 6.180640697479248\n",
      "Epoch [224/1000] Batch [0/23] Loss D: 0.0033158434089273214, Loss G: 9.646623611450195\n",
      "Epoch [225/1000] Batch [0/23] Loss D: 0.0034705819562077522, Loss G: 6.4518513679504395\n",
      "Epoch [226/1000] Batch [0/23] Loss D: 0.003801472717896104, Loss G: 6.166790962219238\n",
      "Epoch [227/1000] Batch [0/23] Loss D: 0.0039350721053779125, Loss G: 9.326011657714844\n",
      "Epoch [228/1000] Batch [0/23] Loss D: 0.021151766180992126, Loss G: 10.424422264099121\n",
      "Epoch [229/1000] Batch [0/23] Loss D: 0.0011015302734449506, Loss G: 8.34163761138916\n",
      "Epoch [230/1000] Batch [0/23] Loss D: 0.004630842246115208, Loss G: 11.552445411682129\n",
      "Epoch [231/1000] Batch [0/23] Loss D: 0.006015649996697903, Loss G: 10.175657272338867\n",
      "Epoch [232/1000] Batch [0/23] Loss D: 0.11624614894390106, Loss G: 9.47789192199707\n",
      "Epoch [233/1000] Batch [0/23] Loss D: 0.0009826369350776076, Loss G: 9.573894500732422\n",
      "Epoch [234/1000] Batch [0/23] Loss D: 0.001178664155304432, Loss G: 10.372238159179688\n",
      "Epoch [235/1000] Batch [0/23] Loss D: 0.0003882682358380407, Loss G: 17.27526092529297\n",
      "Epoch [236/1000] Batch [0/23] Loss D: 0.01861339434981346, Loss G: 7.7541913986206055\n",
      "Epoch [237/1000] Batch [0/23] Loss D: 0.00022403440380003303, Loss G: 7.518161773681641\n",
      "Epoch [238/1000] Batch [0/23] Loss D: 0.001241671503521502, Loss G: 6.019708633422852\n",
      "Epoch [239/1000] Batch [0/23] Loss D: 0.00021429832850117236, Loss G: 11.041332244873047\n",
      "Epoch [240/1000] Batch [0/23] Loss D: 0.004405627027153969, Loss G: 10.252935409545898\n",
      "Epoch [241/1000] Batch [0/23] Loss D: 0.0035747261717915535, Loss G: 7.081874370574951\n",
      "Epoch [242/1000] Batch [0/23] Loss D: 0.0021016616374254227, Loss G: 6.810425758361816\n",
      "Epoch [243/1000] Batch [0/23] Loss D: 0.06487368047237396, Loss G: 4.566474914550781\n",
      "Epoch [244/1000] Batch [0/23] Loss D: 0.0010984763503074646, Loss G: 4.40528678894043\n",
      "Epoch [245/1000] Batch [0/23] Loss D: 0.00017428431601729244, Loss G: 9.063692092895508\n",
      "Epoch [246/1000] Batch [0/23] Loss D: 0.008051106706261635, Loss G: 5.797053813934326\n",
      "Epoch [247/1000] Batch [0/23] Loss D: 0.0007406102959066629, Loss G: 8.792058944702148\n",
      "Epoch [248/1000] Batch [0/23] Loss D: 0.004736047703772783, Loss G: 9.595354080200195\n",
      "Epoch [249/1000] Batch [0/23] Loss D: 0.010666470974683762, Loss G: 7.750860214233398\n",
      "Epoch [250/1000] Batch [0/23] Loss D: 0.0029650346841663122, Loss G: 8.598255157470703\n",
      "Epoch [251/1000] Batch [0/23] Loss D: 0.00036935898242518306, Loss G: 5.787017822265625\n",
      "Epoch [252/1000] Batch [0/23] Loss D: 0.0017381526995450258, Loss G: 6.326551914215088\n",
      "Epoch [253/1000] Batch [0/23] Loss D: 0.0012851195642724633, Loss G: 6.385332107543945\n",
      "Epoch [254/1000] Batch [0/23] Loss D: 0.00012296460045035928, Loss G: 11.283616065979004\n",
      "Epoch [255/1000] Batch [0/23] Loss D: 0.0007606956060044467, Loss G: 8.246758460998535\n",
      "Epoch [256/1000] Batch [0/23] Loss D: 0.009632778353989124, Loss G: 8.951372146606445\n",
      "Epoch [257/1000] Batch [0/23] Loss D: 0.01562984474003315, Loss G: 11.085759162902832\n",
      "Epoch [258/1000] Batch [0/23] Loss D: 0.005337233655154705, Loss G: 4.227333068847656\n",
      "Epoch [259/1000] Batch [0/23] Loss D: 0.003859397955238819, Loss G: 13.992167472839355\n",
      "Epoch [260/1000] Batch [0/23] Loss D: 0.2741905152797699, Loss G: 6.069195747375488\n",
      "Epoch [261/1000] Batch [0/23] Loss D: 0.012501245364546776, Loss G: 7.923844337463379\n",
      "Epoch [262/1000] Batch [0/23] Loss D: 3.800630656769499e-05, Loss G: 20.4935245513916\n",
      "Epoch [263/1000] Batch [0/23] Loss D: 2.4759327061474323e-05, Loss G: 18.89276885986328\n",
      "Epoch [264/1000] Batch [0/23] Loss D: 0.001150869531556964, Loss G: 9.03616714477539\n",
      "Epoch [265/1000] Batch [0/23] Loss D: 0.0791768729686737, Loss G: 8.565195083618164\n",
      "Epoch [266/1000] Batch [0/23] Loss D: 0.016429593786597252, Loss G: 8.46198844909668\n",
      "Epoch [267/1000] Batch [0/23] Loss D: 0.16031478345394135, Loss G: 10.856828689575195\n",
      "Epoch [268/1000] Batch [0/23] Loss D: 0.004896520636975765, Loss G: 15.501310348510742\n",
      "Epoch [269/1000] Batch [0/23] Loss D: 0.00014637493586633354, Loss G: 7.131747245788574\n",
      "Epoch [270/1000] Batch [0/23] Loss D: 0.04645272344350815, Loss G: 9.576711654663086\n",
      "Epoch [271/1000] Batch [0/23] Loss D: 0.0016189694870263338, Loss G: 9.78862476348877\n",
      "Epoch [272/1000] Batch [0/23] Loss D: 0.0063710263930261135, Loss G: 8.100607872009277\n",
      "Epoch [273/1000] Batch [0/23] Loss D: 0.0045442357659339905, Loss G: 3.7629318237304688\n",
      "Epoch [274/1000] Batch [0/23] Loss D: 0.008167499676346779, Loss G: 3.1591076850891113\n",
      "Epoch [275/1000] Batch [0/23] Loss D: 0.005167576018720865, Loss G: 5.6319990158081055\n",
      "Epoch [276/1000] Batch [0/23] Loss D: 0.005191444884985685, Loss G: 7.508003234863281\n",
      "Epoch [277/1000] Batch [0/23] Loss D: 0.0021182214841246605, Loss G: 8.737874984741211\n",
      "Epoch [278/1000] Batch [0/23] Loss D: 0.008703074418008327, Loss G: 7.453802108764648\n",
      "Epoch [279/1000] Batch [0/23] Loss D: 0.015083027072250843, Loss G: 7.573345184326172\n",
      "Epoch [280/1000] Batch [0/23] Loss D: 0.0008877052459865808, Loss G: 13.019365310668945\n",
      "Epoch [281/1000] Batch [0/23] Loss D: 0.005455175880342722, Loss G: 8.521393775939941\n",
      "Epoch [282/1000] Batch [0/23] Loss D: 0.11112908273935318, Loss G: 5.335325241088867\n",
      "Epoch [283/1000] Batch [0/23] Loss D: 0.08678895980119705, Loss G: 7.318326950073242\n",
      "Epoch [284/1000] Batch [0/23] Loss D: 8.112588693620637e-05, Loss G: 23.494016647338867\n",
      "Epoch [285/1000] Batch [0/23] Loss D: 0.3274390995502472, Loss G: 25.94869613647461\n",
      "Epoch [286/1000] Batch [0/23] Loss D: 0.0002373198512941599, Loss G: 22.371654510498047\n",
      "Epoch [287/1000] Batch [0/23] Loss D: 0.014412439428269863, Loss G: 14.803865432739258\n",
      "Epoch [288/1000] Batch [0/23] Loss D: 7.254331285366789e-05, Loss G: 14.134803771972656\n",
      "Epoch [289/1000] Batch [0/23] Loss D: 0.22157439589500427, Loss G: 14.647409439086914\n",
      "Epoch [290/1000] Batch [0/23] Loss D: 0.014494449831545353, Loss G: 24.055261611938477\n",
      "Epoch [291/1000] Batch [0/23] Loss D: 0.035644907504320145, Loss G: 12.961499214172363\n",
      "Epoch [292/1000] Batch [0/23] Loss D: 0.03206407651305199, Loss G: 7.487009048461914\n",
      "Epoch [293/1000] Batch [0/23] Loss D: 0.10922424495220184, Loss G: 9.233908653259277\n",
      "Epoch [294/1000] Batch [0/23] Loss D: 0.007092962507158518, Loss G: 5.195844650268555\n",
      "Epoch [295/1000] Batch [0/23] Loss D: 0.6707718968391418, Loss G: 21.130237579345703\n",
      "Epoch [296/1000] Batch [0/23] Loss D: 0.07634227722883224, Loss G: 7.460355281829834\n",
      "Epoch [297/1000] Batch [0/23] Loss D: 0.002857270883396268, Loss G: 10.443140029907227\n",
      "Epoch [298/1000] Batch [0/23] Loss D: 0.00041219868580810726, Loss G: 10.130824089050293\n",
      "Epoch [299/1000] Batch [0/23] Loss D: 0.6728051900863647, Loss G: 16.90264892578125\n",
      "Epoch [300/1000] Batch [0/23] Loss D: 0.0009413538500666618, Loss G: 8.056697845458984\n",
      "Epoch [301/1000] Batch [0/23] Loss D: 0.03966335579752922, Loss G: 3.265047073364258\n",
      "Epoch [302/1000] Batch [0/23] Loss D: 0.0018673704471439123, Loss G: 5.64210319519043\n",
      "Epoch [303/1000] Batch [0/23] Loss D: 3.2897361961659044e-05, Loss G: 15.943967819213867\n",
      "Epoch [304/1000] Batch [0/23] Loss D: 0.0003403094888199121, Loss G: 20.639724731445312\n",
      "Epoch [305/1000] Batch [0/23] Loss D: 0.44062110781669617, Loss G: 3.1702466011047363\n",
      "Epoch [306/1000] Batch [0/23] Loss D: 0.3140920400619507, Loss G: 23.001224517822266\n",
      "Epoch [307/1000] Batch [0/23] Loss D: 0.15085794031620026, Loss G: 13.797658920288086\n",
      "Epoch [308/1000] Batch [0/23] Loss D: 0.0013897978933528066, Loss G: 9.853769302368164\n",
      "Epoch [309/1000] Batch [0/23] Loss D: 0.03133603185415268, Loss G: 20.972946166992188\n",
      "Epoch [310/1000] Batch [0/23] Loss D: 0.05820392072200775, Loss G: 10.76058578491211\n",
      "Epoch [311/1000] Batch [0/23] Loss D: 0.030499078333377838, Loss G: 5.024753093719482\n",
      "Epoch [312/1000] Batch [0/23] Loss D: 0.0078800143674016, Loss G: 6.003764629364014\n",
      "Epoch [313/1000] Batch [0/23] Loss D: 0.018578484654426575, Loss G: 5.096842288970947\n",
      "Epoch [314/1000] Batch [0/23] Loss D: 0.003356490284204483, Loss G: 6.32058048248291\n",
      "Epoch [315/1000] Batch [0/23] Loss D: 0.0442831926047802, Loss G: 7.912775039672852\n",
      "Epoch [316/1000] Batch [0/23] Loss D: 0.09313616901636124, Loss G: 3.5324535369873047\n",
      "Epoch [317/1000] Batch [0/23] Loss D: 0.0014899091329425573, Loss G: 6.9348015785217285\n",
      "Epoch [318/1000] Batch [0/23] Loss D: 0.005679272580891848, Loss G: 5.275679588317871\n",
      "Epoch [319/1000] Batch [0/23] Loss D: 0.004063369706273079, Loss G: 8.798900604248047\n",
      "Epoch [320/1000] Batch [0/23] Loss D: 0.000935582909733057, Loss G: 5.516424655914307\n",
      "Epoch [321/1000] Batch [0/23] Loss D: 0.0003046014462597668, Loss G: 13.09126091003418\n",
      "Epoch [322/1000] Batch [0/23] Loss D: 0.009942975826561451, Loss G: 8.989748001098633\n",
      "Epoch [323/1000] Batch [0/23] Loss D: 0.022267622873187065, Loss G: 6.054445266723633\n",
      "Epoch [324/1000] Batch [0/23] Loss D: 0.0028494209982454777, Loss G: 6.85264778137207\n",
      "Epoch [325/1000] Batch [0/23] Loss D: 0.004954937845468521, Loss G: 6.093195915222168\n",
      "Epoch [326/1000] Batch [0/23] Loss D: 0.0011944214347749949, Loss G: 11.402632713317871\n",
      "Epoch [327/1000] Batch [0/23] Loss D: 0.01079842634499073, Loss G: 7.67951774597168\n",
      "Epoch [328/1000] Batch [0/23] Loss D: 0.0008895528153516352, Loss G: 10.926653861999512\n",
      "Epoch [329/1000] Batch [0/23] Loss D: 0.0028002276085317135, Loss G: 6.687259197235107\n",
      "Epoch [330/1000] Batch [0/23] Loss D: 0.9736624956130981, Loss G: 24.49748992919922\n",
      "Epoch [331/1000] Batch [0/23] Loss D: 9.426515316590667e-05, Loss G: 14.599527359008789\n",
      "Epoch [332/1000] Batch [0/23] Loss D: 0.023296140134334564, Loss G: 11.686294555664062\n",
      "Epoch [333/1000] Batch [0/23] Loss D: 0.00557576771825552, Loss G: 7.421003341674805\n",
      "Epoch [334/1000] Batch [0/23] Loss D: 0.0009222271619364619, Loss G: 6.585969924926758\n",
      "Epoch [335/1000] Batch [0/23] Loss D: 0.04702207073569298, Loss G: 10.089699745178223\n",
      "Epoch [336/1000] Batch [0/23] Loss D: 0.025562558323144913, Loss G: 14.812408447265625\n",
      "Epoch [337/1000] Batch [0/23] Loss D: 0.003646387252956629, Loss G: 5.135533332824707\n",
      "Epoch [338/1000] Batch [0/23] Loss D: 0.008305053226649761, Loss G: 11.286081314086914\n",
      "Epoch [339/1000] Batch [0/23] Loss D: 0.000685133330989629, Loss G: 11.2566556930542\n",
      "Epoch [340/1000] Batch [0/23] Loss D: 0.008285729214549065, Loss G: 11.030241012573242\n",
      "Epoch [341/1000] Batch [0/23] Loss D: 0.0007745682960376143, Loss G: 9.452205657958984\n",
      "Epoch [342/1000] Batch [0/23] Loss D: 0.00201023044064641, Loss G: 15.089496612548828\n",
      "Epoch [343/1000] Batch [0/23] Loss D: 0.11107534170150757, Loss G: 18.455055236816406\n",
      "Epoch [344/1000] Batch [0/23] Loss D: 0.037409305572509766, Loss G: 9.319612503051758\n",
      "Epoch [345/1000] Batch [0/23] Loss D: 0.001482966705225408, Loss G: 8.706521987915039\n",
      "Epoch [346/1000] Batch [0/23] Loss D: 0.0066517312079668045, Loss G: 4.815847396850586\n",
      "Epoch [347/1000] Batch [0/23] Loss D: 0.0011166419135406613, Loss G: 6.702182769775391\n",
      "Epoch [348/1000] Batch [0/23] Loss D: 0.0005846176063641906, Loss G: 7.546410083770752\n",
      "Epoch [349/1000] Batch [0/23] Loss D: 0.014592660591006279, Loss G: 5.694768905639648\n",
      "Epoch [350/1000] Batch [0/23] Loss D: 0.00810195505619049, Loss G: 3.795656204223633\n",
      "Epoch [351/1000] Batch [0/23] Loss D: 0.030387403443455696, Loss G: 9.725049018859863\n",
      "Epoch [352/1000] Batch [0/23] Loss D: 0.0005584523314610124, Loss G: 6.282192707061768\n",
      "Epoch [353/1000] Batch [0/23] Loss D: 0.000731440435629338, Loss G: 15.880765914916992\n",
      "Epoch [354/1000] Batch [0/23] Loss D: 0.0012408382026478648, Loss G: 9.144874572753906\n",
      "Epoch [355/1000] Batch [0/23] Loss D: 0.00251894723623991, Loss G: 8.573925971984863\n",
      "Epoch [356/1000] Batch [0/23] Loss D: 0.0038827613461762667, Loss G: 14.72291088104248\n",
      "Epoch [357/1000] Batch [0/23] Loss D: 0.0008863166440278292, Loss G: 9.013803482055664\n",
      "Epoch [358/1000] Batch [0/23] Loss D: 0.00536106713116169, Loss G: 5.161262512207031\n",
      "Epoch [359/1000] Batch [0/23] Loss D: 0.008929167874157429, Loss G: 12.486360549926758\n",
      "Epoch [360/1000] Batch [0/23] Loss D: 0.013235477730631828, Loss G: 6.542747497558594\n",
      "Epoch [361/1000] Batch [0/23] Loss D: 0.001711085787974298, Loss G: 5.32687520980835\n",
      "Epoch [362/1000] Batch [0/23] Loss D: 0.002163949655368924, Loss G: 9.505608558654785\n",
      "Epoch [363/1000] Batch [0/23] Loss D: 0.0003961920738220215, Loss G: 10.838350296020508\n",
      "Epoch [364/1000] Batch [0/23] Loss D: 0.027792150154709816, Loss G: 15.083547592163086\n",
      "Epoch [365/1000] Batch [0/23] Loss D: 0.06462620198726654, Loss G: 12.803566932678223\n",
      "Epoch [366/1000] Batch [0/23] Loss D: 0.01139989122748375, Loss G: 8.835433959960938\n",
      "Epoch [367/1000] Batch [0/23] Loss D: 0.004460242111235857, Loss G: 9.680228233337402\n",
      "Epoch [368/1000] Batch [0/23] Loss D: 0.001591784181073308, Loss G: 8.767600059509277\n",
      "Epoch [369/1000] Batch [0/23] Loss D: 0.03366973251104355, Loss G: 8.133040428161621\n",
      "Epoch [370/1000] Batch [0/23] Loss D: 0.0012702294625341892, Loss G: 3.544802188873291\n",
      "Epoch [371/1000] Batch [0/23] Loss D: 0.0027032671496272087, Loss G: 6.039687633514404\n",
      "Epoch [372/1000] Batch [0/23] Loss D: 0.009503079578280449, Loss G: 8.504497528076172\n",
      "Epoch [373/1000] Batch [0/23] Loss D: 0.0035775022115558386, Loss G: 8.41316032409668\n",
      "Epoch [374/1000] Batch [0/23] Loss D: 0.20634138584136963, Loss G: 18.205673217773438\n",
      "Epoch [375/1000] Batch [0/23] Loss D: 0.00025557767366990447, Loss G: 16.965503692626953\n",
      "Epoch [376/1000] Batch [0/23] Loss D: 0.0005145116592757404, Loss G: 23.507051467895508\n",
      "Epoch [377/1000] Batch [0/23] Loss D: 0.02198570780456066, Loss G: 7.873797416687012\n",
      "Epoch [378/1000] Batch [0/23] Loss D: 2.9652073862962425e-05, Loss G: 15.383333206176758\n",
      "Epoch [379/1000] Batch [0/23] Loss D: 0.3117348849773407, Loss G: 15.833877563476562\n",
      "Epoch [380/1000] Batch [0/23] Loss D: 0.00411085644736886, Loss G: 6.058708667755127\n",
      "Epoch [381/1000] Batch [0/23] Loss D: 0.0020393086597323418, Loss G: 10.096685409545898\n",
      "Epoch [382/1000] Batch [0/23] Loss D: 0.0025353622622787952, Loss G: 5.0785956382751465\n",
      "Epoch [383/1000] Batch [0/23] Loss D: 0.002850242657586932, Loss G: 7.879461288452148\n",
      "Epoch [384/1000] Batch [0/23] Loss D: 0.020874284207820892, Loss G: 6.621907711029053\n",
      "Epoch [385/1000] Batch [0/23] Loss D: 0.0016403973568230867, Loss G: 4.428894996643066\n",
      "Epoch [386/1000] Batch [0/23] Loss D: 0.0014886457938700914, Loss G: 8.214004516601562\n",
      "Epoch [387/1000] Batch [0/23] Loss D: 0.0016664270078763366, Loss G: 9.58371353149414\n",
      "Epoch [388/1000] Batch [0/23] Loss D: 0.0019896929152309895, Loss G: 9.020241737365723\n",
      "Epoch [389/1000] Batch [0/23] Loss D: 0.0008694889838807285, Loss G: 9.134662628173828\n",
      "Epoch [390/1000] Batch [0/23] Loss D: 0.028686372563242912, Loss G: 15.178900718688965\n",
      "Epoch [391/1000] Batch [0/23] Loss D: 0.002636829623952508, Loss G: 8.537019729614258\n",
      "Epoch [392/1000] Batch [0/23] Loss D: 0.003862530691549182, Loss G: 7.688653945922852\n",
      "Epoch [393/1000] Batch [0/23] Loss D: 0.020032918080687523, Loss G: 4.884402751922607\n",
      "Epoch [394/1000] Batch [0/23] Loss D: 3.7819518183823675e-05, Loss G: 15.521503448486328\n",
      "Epoch [395/1000] Batch [0/23] Loss D: 0.003124913200736046, Loss G: 9.033010482788086\n",
      "Epoch [396/1000] Batch [0/23] Loss D: 0.0015059991274029016, Loss G: 7.5772624015808105\n",
      "Epoch [397/1000] Batch [0/23] Loss D: 0.02728765271604061, Loss G: 15.07882308959961\n",
      "Epoch [398/1000] Batch [0/23] Loss D: 0.012867549434304237, Loss G: 6.168659210205078\n",
      "Epoch [399/1000] Batch [0/23] Loss D: 0.002426307648420334, Loss G: 6.147564888000488\n",
      "Epoch [400/1000] Batch [0/23] Loss D: 0.004152290523052216, Loss G: 17.93036651611328\n",
      "Epoch [401/1000] Batch [0/23] Loss D: 0.23161280155181885, Loss G: 13.867067337036133\n",
      "Epoch [402/1000] Batch [0/23] Loss D: 0.09412434697151184, Loss G: 11.504156112670898\n",
      "Epoch [403/1000] Batch [0/23] Loss D: 0.006168113090097904, Loss G: 15.270933151245117\n",
      "Epoch [404/1000] Batch [0/23] Loss D: 0.005684961564838886, Loss G: 4.272858142852783\n",
      "Epoch [405/1000] Batch [0/23] Loss D: 0.009565635584294796, Loss G: 8.385444641113281\n",
      "Epoch [406/1000] Batch [0/23] Loss D: 0.00017720981850288808, Loss G: 9.420702934265137\n",
      "Epoch [407/1000] Batch [0/23] Loss D: 0.0022715735249221325, Loss G: 9.084236145019531\n",
      "Epoch [408/1000] Batch [0/23] Loss D: 0.02727709896862507, Loss G: 6.566306114196777\n",
      "Epoch [409/1000] Batch [0/23] Loss D: 0.0002341692743357271, Loss G: 9.634721755981445\n",
      "Epoch [410/1000] Batch [0/23] Loss D: 0.016505632549524307, Loss G: 6.423287391662598\n",
      "Epoch [411/1000] Batch [0/23] Loss D: 0.03846953436732292, Loss G: 19.889251708984375\n",
      "Epoch [412/1000] Batch [0/23] Loss D: 0.011415103450417519, Loss G: 5.520083427429199\n",
      "Epoch [413/1000] Batch [0/23] Loss D: 0.03407019004225731, Loss G: 2.133511781692505\n",
      "Epoch [414/1000] Batch [0/23] Loss D: 0.15527033805847168, Loss G: 15.431427001953125\n",
      "Epoch [415/1000] Batch [0/23] Loss D: 0.6821199655532837, Loss G: 8.419035911560059\n",
      "Epoch [416/1000] Batch [0/23] Loss D: 0.08978000283241272, Loss G: 20.807741165161133\n",
      "Epoch [417/1000] Batch [0/23] Loss D: 0.005757071077823639, Loss G: 9.161273956298828\n",
      "Epoch [418/1000] Batch [0/23] Loss D: 0.003886127844452858, Loss G: 7.421141624450684\n",
      "Epoch [419/1000] Batch [0/23] Loss D: 0.02657916024327278, Loss G: 6.991423606872559\n",
      "Epoch [420/1000] Batch [0/23] Loss D: 0.0031446414068341255, Loss G: 10.629454612731934\n",
      "Epoch [421/1000] Batch [0/23] Loss D: 0.0004931756411679089, Loss G: 6.469223976135254\n",
      "Epoch [422/1000] Batch [0/23] Loss D: 0.00814420823007822, Loss G: 8.464229583740234\n",
      "Epoch [423/1000] Batch [0/23] Loss D: 0.0007184013957157731, Loss G: 6.594743728637695\n",
      "Epoch [424/1000] Batch [0/23] Loss D: 0.0006894883117638528, Loss G: 11.10007095336914\n",
      "Epoch [425/1000] Batch [0/23] Loss D: 0.00022438028827309608, Loss G: 7.577773094177246\n",
      "Epoch [426/1000] Batch [0/23] Loss D: 0.0006049542571417987, Loss G: 7.638617515563965\n",
      "Epoch [427/1000] Batch [0/23] Loss D: 0.000341197126545012, Loss G: 7.2696099281311035\n",
      "Epoch [428/1000] Batch [0/23] Loss D: 0.0185034591704607, Loss G: 7.483793258666992\n",
      "Epoch [429/1000] Batch [0/23] Loss D: 0.011275864206254482, Loss G: 7.348780632019043\n",
      "Epoch [430/1000] Batch [0/23] Loss D: 0.06017383933067322, Loss G: 8.162454605102539\n",
      "Epoch [431/1000] Batch [0/23] Loss D: 0.003407346550375223, Loss G: 8.742530822753906\n",
      "Epoch [432/1000] Batch [0/23] Loss D: 0.024988099932670593, Loss G: 7.913978576660156\n",
      "Epoch [433/1000] Batch [0/23] Loss D: 0.0008431131718680263, Loss G: 9.18120002746582\n",
      "Epoch [434/1000] Batch [0/23] Loss D: 0.0033140613231807947, Loss G: 4.5906171798706055\n",
      "Epoch [435/1000] Batch [0/23] Loss D: 0.0071630943566560745, Loss G: 8.930908203125\n",
      "Epoch [436/1000] Batch [0/23] Loss D: 0.0018008860060945153, Loss G: 9.052264213562012\n",
      "Epoch [437/1000] Batch [0/23] Loss D: 0.000510142941493541, Loss G: 9.316555976867676\n",
      "Epoch [438/1000] Batch [0/23] Loss D: 0.0002488153986632824, Loss G: 8.372417449951172\n",
      "Epoch [439/1000] Batch [0/23] Loss D: 9.647622937336564e-05, Loss G: 13.70579719543457\n",
      "Epoch [440/1000] Batch [0/23] Loss D: 0.0002037561498582363, Loss G: 14.01248836517334\n",
      "Epoch [441/1000] Batch [0/23] Loss D: 0.12579134106636047, Loss G: 23.955415725708008\n",
      "Epoch [442/1000] Batch [0/23] Loss D: 0.0002485073637217283, Loss G: 10.597990036010742\n",
      "Epoch [443/1000] Batch [0/23] Loss D: 0.001900927978567779, Loss G: 6.4875993728637695\n",
      "Epoch [444/1000] Batch [0/23] Loss D: 0.004111438989639282, Loss G: 9.703536987304688\n",
      "Epoch [445/1000] Batch [0/23] Loss D: 0.0014650535304099321, Loss G: 8.524022102355957\n",
      "Epoch [446/1000] Batch [0/23] Loss D: 0.005578941199928522, Loss G: 7.2859649658203125\n",
      "Epoch [447/1000] Batch [0/23] Loss D: 0.007502666674554348, Loss G: 7.391095161437988\n",
      "Epoch [448/1000] Batch [0/23] Loss D: 0.0029790792614221573, Loss G: 10.827322959899902\n",
      "Epoch [449/1000] Batch [0/23] Loss D: 0.00020154163939878345, Loss G: 20.45084571838379\n",
      "Epoch [450/1000] Batch [0/23] Loss D: 2.440062587538705e-07, Loss G: 9.718445777893066\n",
      "Epoch [451/1000] Batch [0/23] Loss D: 1.9559714928618632e-05, Loss G: 12.038411140441895\n",
      "Epoch [452/1000] Batch [0/23] Loss D: 0.0009661005460657179, Loss G: 7.739963531494141\n",
      "Epoch [453/1000] Batch [0/23] Loss D: 0.003474860219284892, Loss G: 11.420858383178711\n",
      "Epoch [454/1000] Batch [0/23] Loss D: 0.00026973377680405974, Loss G: 15.848098754882812\n",
      "Epoch [455/1000] Batch [0/23] Loss D: 0.0008844656404107809, Loss G: 13.67960262298584\n",
      "Epoch [456/1000] Batch [0/23] Loss D: 6.979185855016112e-06, Loss G: 11.580255508422852\n",
      "Epoch [457/1000] Batch [0/23] Loss D: 0.44964686036109924, Loss G: 38.561561584472656\n",
      "Epoch [458/1000] Batch [0/23] Loss D: 0.10211067646741867, Loss G: 15.938545227050781\n",
      "Epoch [459/1000] Batch [0/23] Loss D: 1.1760945320129395, Loss G: 27.511272430419922\n",
      "Epoch [460/1000] Batch [0/23] Loss D: 0.06813541799783707, Loss G: 21.7125244140625\n",
      "Epoch [461/1000] Batch [0/23] Loss D: 0.0018435257952660322, Loss G: 11.769270896911621\n",
      "Epoch [462/1000] Batch [0/23] Loss D: 0.13477033376693726, Loss G: 10.556585311889648\n",
      "Epoch [463/1000] Batch [0/23] Loss D: 0.036903295665979385, Loss G: 13.685317993164062\n",
      "Epoch [464/1000] Batch [0/23] Loss D: 0.06460925191640854, Loss G: 10.640571594238281\n",
      "Epoch [465/1000] Batch [0/23] Loss D: 0.00600641593337059, Loss G: 4.754979133605957\n",
      "Epoch [466/1000] Batch [0/23] Loss D: 0.21207144856452942, Loss G: 17.74502182006836\n",
      "Epoch [467/1000] Batch [0/23] Loss D: 0.02477051317691803, Loss G: 14.548152923583984\n",
      "Epoch [468/1000] Batch [0/23] Loss D: 9.209255949826911e-05, Loss G: 11.02122688293457\n",
      "Epoch [469/1000] Batch [0/23] Loss D: 0.0011281847255304456, Loss G: 12.139724731445312\n",
      "Epoch [470/1000] Batch [0/23] Loss D: 0.001484562992118299, Loss G: 12.585821151733398\n",
      "Epoch [471/1000] Batch [0/23] Loss D: 0.039290327578783035, Loss G: 15.094367980957031\n",
      "Epoch [472/1000] Batch [0/23] Loss D: 0.07530882209539413, Loss G: 10.468334197998047\n",
      "Epoch [473/1000] Batch [0/23] Loss D: 0.0007072216249071062, Loss G: 12.87462043762207\n",
      "Epoch [474/1000] Batch [0/23] Loss D: 0.00016406967188231647, Loss G: 13.067866325378418\n",
      "Epoch [475/1000] Batch [0/23] Loss D: 0.026576777920126915, Loss G: 8.063952445983887\n",
      "Epoch [476/1000] Batch [0/23] Loss D: 1.3738845586776733, Loss G: 21.887727737426758\n",
      "Epoch [477/1000] Batch [0/23] Loss D: 9.210654752678238e-06, Loss G: 11.75451374053955\n",
      "Epoch [478/1000] Batch [0/23] Loss D: 0.003227303270250559, Loss G: 12.39511489868164\n",
      "Epoch [479/1000] Batch [0/23] Loss D: 0.004589196760207415, Loss G: 7.995514869689941\n",
      "Epoch [480/1000] Batch [0/23] Loss D: 0.01140980888158083, Loss G: 11.035234451293945\n",
      "Epoch [481/1000] Batch [0/23] Loss D: 0.00041394022991880774, Loss G: 7.7873382568359375\n",
      "Epoch [482/1000] Batch [0/23] Loss D: 0.002547151641920209, Loss G: 4.942579746246338\n",
      "Epoch [483/1000] Batch [0/23] Loss D: 0.11433803290128708, Loss G: 11.041463851928711\n",
      "Epoch [484/1000] Batch [0/23] Loss D: 0.006430285517126322, Loss G: 7.027915000915527\n",
      "Epoch [485/1000] Batch [0/23] Loss D: 0.0038590282201766968, Loss G: 7.7902421951293945\n",
      "Epoch [486/1000] Batch [0/23] Loss D: 0.0044771102257072926, Loss G: 7.441484451293945\n",
      "Epoch [487/1000] Batch [0/23] Loss D: 0.019114334136247635, Loss G: 7.073800086975098\n",
      "Epoch [488/1000] Batch [0/23] Loss D: 6.650762770732399e-06, Loss G: 19.04928207397461\n",
      "Epoch [489/1000] Batch [0/23] Loss D: 0.0007341854507103562, Loss G: 9.001899719238281\n",
      "Epoch [490/1000] Batch [0/23] Loss D: 0.005693717859685421, Loss G: 7.112138748168945\n",
      "Epoch [491/1000] Batch [0/23] Loss D: 0.001520955702289939, Loss G: 6.513155937194824\n",
      "Epoch [492/1000] Batch [0/23] Loss D: 0.00398479588329792, Loss G: 5.366782188415527\n",
      "Epoch [493/1000] Batch [0/23] Loss D: 0.008477327413856983, Loss G: 10.706127166748047\n",
      "Epoch [494/1000] Batch [0/23] Loss D: 0.00023052332107909024, Loss G: 10.65549087524414\n",
      "Epoch [495/1000] Batch [0/23] Loss D: 0.08681981265544891, Loss G: 14.772043228149414\n",
      "Epoch [496/1000] Batch [0/23] Loss D: 0.0024750421289354563, Loss G: 5.4547600746154785\n",
      "Epoch [497/1000] Batch [0/23] Loss D: 0.06806755810976028, Loss G: 8.860570907592773\n",
      "Epoch [498/1000] Batch [0/23] Loss D: 0.01720917783677578, Loss G: 14.736835479736328\n",
      "Epoch [499/1000] Batch [0/23] Loss D: 0.0017000176012516022, Loss G: 7.025514125823975\n",
      "Epoch [500/1000] Batch [0/23] Loss D: 0.0011609407374635339, Loss G: 10.104277610778809\n",
      "Epoch [501/1000] Batch [0/23] Loss D: 0.06824754923582077, Loss G: 22.90674591064453\n",
      "Epoch [502/1000] Batch [0/23] Loss D: 0.02608766220510006, Loss G: 13.840941429138184\n",
      "Epoch [503/1000] Batch [0/23] Loss D: 2.092266798019409, Loss G: 44.89231491088867\n",
      "Epoch [504/1000] Batch [0/23] Loss D: 1.6288907527923584, Loss G: 20.178604125976562\n",
      "Epoch [505/1000] Batch [0/23] Loss D: 0.00011995170643785968, Loss G: 8.19914436340332\n",
      "Epoch [506/1000] Batch [0/23] Loss D: 2.587127923965454, Loss G: 37.55363464355469\n",
      "Epoch [507/1000] Batch [0/23] Loss D: 0.00045338523341342807, Loss G: 11.9387845993042\n",
      "Epoch [508/1000] Batch [0/23] Loss D: 0.030605649575591087, Loss G: 29.873432159423828\n",
      "Epoch [509/1000] Batch [0/23] Loss D: 0.03091205097734928, Loss G: 7.617624282836914\n",
      "Epoch [510/1000] Batch [0/23] Loss D: 0.02131071500480175, Loss G: 15.13870620727539\n",
      "Epoch [511/1000] Batch [0/23] Loss D: 3.1560935894958675e-05, Loss G: 13.25080394744873\n",
      "Epoch [512/1000] Batch [0/23] Loss D: 0.00555143179371953, Loss G: 7.122406005859375\n",
      "Epoch [513/1000] Batch [0/23] Loss D: 3.7398291169665754e-05, Loss G: 14.636945724487305\n",
      "Epoch [514/1000] Batch [0/23] Loss D: 0.003601154312491417, Loss G: 7.379181861877441\n",
      "Epoch [515/1000] Batch [0/23] Loss D: 0.05574449524283409, Loss G: 10.955997467041016\n",
      "Epoch [516/1000] Batch [0/23] Loss D: 0.003750384086742997, Loss G: 11.138802528381348\n",
      "Epoch [517/1000] Batch [0/23] Loss D: 0.0027853697538375854, Loss G: 8.370574951171875\n",
      "Epoch [518/1000] Batch [0/23] Loss D: 0.0016679603140801191, Loss G: 10.125625610351562\n",
      "Epoch [519/1000] Batch [0/23] Loss D: 0.016883445903658867, Loss G: 6.452023029327393\n",
      "Epoch [520/1000] Batch [0/23] Loss D: 0.00037400974542833865, Loss G: 11.214554786682129\n",
      "Epoch [521/1000] Batch [0/23] Loss D: 0.02698582224547863, Loss G: 12.764500617980957\n",
      "Epoch [522/1000] Batch [0/23] Loss D: 0.0005007139989174902, Loss G: 7.347842216491699\n",
      "Epoch [523/1000] Batch [0/23] Loss D: 0.0028439913876354694, Loss G: 8.908187866210938\n",
      "Epoch [524/1000] Batch [0/23] Loss D: 0.11734651774168015, Loss G: 22.083175659179688\n",
      "Epoch [525/1000] Batch [0/23] Loss D: 0.020426802337169647, Loss G: 9.200626373291016\n",
      "Epoch [526/1000] Batch [0/23] Loss D: 0.003579416312277317, Loss G: 6.671559810638428\n",
      "Epoch [527/1000] Batch [0/23] Loss D: 0.07024703919887543, Loss G: 5.807070255279541\n",
      "Epoch [528/1000] Batch [0/23] Loss D: 0.006922352593392134, Loss G: 19.99736213684082\n",
      "Epoch [529/1000] Batch [0/23] Loss D: 0.0076193902641534805, Loss G: 11.55978012084961\n",
      "Epoch [530/1000] Batch [0/23] Loss D: 0.0018812947673723102, Loss G: 5.482883453369141\n",
      "Epoch [531/1000] Batch [0/23] Loss D: 0.0005575509858317673, Loss G: 13.533753395080566\n",
      "Epoch [532/1000] Batch [0/23] Loss D: 0.012828478589653969, Loss G: 4.813806056976318\n",
      "Epoch [533/1000] Batch [0/23] Loss D: 0.009217788465321064, Loss G: 12.062042236328125\n",
      "Epoch [534/1000] Batch [0/23] Loss D: 0.0029900551307946444, Loss G: 8.686224937438965\n",
      "Epoch [535/1000] Batch [0/23] Loss D: 0.0009428974590264261, Loss G: 13.088006973266602\n",
      "Epoch [536/1000] Batch [0/23] Loss D: 0.006923567969352007, Loss G: 6.769157409667969\n",
      "Epoch [537/1000] Batch [0/23] Loss D: 0.0015602227067574859, Loss G: 10.141108512878418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Train Critic\u001b[39;00m\n\u001b[1;32m      6\u001b[0m netD\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m real_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m real_labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, nz, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in enumerate(dataloader, 0):\n",
    "        batch_size = data.size(0)\n",
    "\n",
    "        # Train Critic\n",
    "        netD.zero_grad()\n",
    "        real_data = data.to(device)\n",
    "        real_labels = labels.to(device)\n",
    "\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake_labels = torch.randint(0, n_classes, (batch_size,), device=device)\n",
    "        fake_data = netG(noise, fake_labels)\n",
    "\n",
    "        real_target = torch.ones(batch_size, device=device)\n",
    "        fake_target = torch.zeros(batch_size, device=device)\n",
    "\n",
    "        d_real_loss = criterion(netD(real_data, real_labels), real_target)\n",
    "        d_fake_loss = criterion(netD(fake_data.detach(), fake_labels), fake_target)\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Train Generator\n",
    "        if i % gen_upd_rate == 0:\n",
    "            netG.zero_grad()\n",
    "            noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "            fake_labels = torch.randint(0, n_classes, (batch_size,), device=device)\n",
    "            fake_data = netG(noise, fake_labels)\n",
    "            g_loss = criterion(netD(fake_data, fake_labels), real_target)\n",
    "            g_loss.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "        if i % loss_show_rate == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}] Batch [{i}/{len(dataloader)}] '\n",
    "                f'Loss D: {d_loss.item()}, Loss G: {g_loss.item()}')\n",
    "\n",
    "        if (i % image_show_rate == 0) and ((epoch + 1) % epoch_show_rate == 0):\n",
    "            with torch.no_grad():\n",
    "                fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "                fixed_labels = torch.randint(0, n_classes, (64,), device=device)\n",
    "                generated_images = netG(fixed_noise, fixed_labels)\n",
    "                # Save or visualize the generated images using Matplotlib or TensorBoard\n",
    "                # Example using Matplotlib:\n",
    "                plt.figure(figsize=(8, 8))\n",
    "                for j in range(64):\n",
    "                    plt.subplot(8, 8, j + 1)\n",
    "                    plt.imshow(generated_images[j].squeeze().cpu().numpy(), cmap='gray')\n",
    "                    plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'generated_images/fonts5_epoch_{epoch+1}_batch_{i}.png')\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_gan_symbols(symbols, amount):\n",
    "    dataset = pd.DataFrame(columns=['path', 'label'])\n",
    "    os.makedirs(\"data/GAN weak/data\", exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        for symbol in symbols:\n",
    "            symbol_class = mapping.unmapping[symbol]\n",
    "            labels = torch.full((amount,), symbol_class, device=device)\n",
    "            noise = torch.randn(amount, nz, 1, 1, device=device)\n",
    "            generated_images = netG(noise, labels)\n",
    "\n",
    "            # Save the generated images as PNG files\n",
    "            for i in range(amount):\n",
    "                image_path = f\"data/GAN weak/data/{symbol}_{i}.png\"\n",
    "                vutils.save_image(generated_images[i], image_path, normalize=True)\n",
    "                dataset.loc[len(dataset)] = [f\"data/GAN weak/data/{symbol}_{i}.png\", symbol]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/GAN weak/data/0_0.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/GAN weak/data/0_1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/GAN weak/data/1_0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/GAN weak/data/1_1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/GAN weak/data/2_0.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         path label\n",
       "0  data/GAN weak/data/0_0.png     0\n",
       "1  data/GAN weak/data/0_1.png     0\n",
       "2  data/GAN weak/data/1_0.png     1\n",
       "3  data/GAN weak/data/1_1.png     1\n",
       "4  data/GAN weak/data/2_0.png     2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabdefghnqrt'\n",
    "# symbols = \"a\"\n",
    "df = generate_gan_symbols(symbols, 2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/GAN/dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
